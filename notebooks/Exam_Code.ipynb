{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import difflib\n",
    "from nltk import agreement\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random #only used for generating 100 random tweets for manual labelling\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, classification_report, roc_auc_score, roc_curve, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All functions for the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the tokenaziation punctuations, emojois, pointless strings and characters are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for stopwords\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported stop_words from nltk library (stopwords includes conjunctions, articles and so on)\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('th')\n",
    "stop_words.append('st')\n",
    "print(\"|\".join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(tweets):\n",
    "    \"\"\"\n",
    "    Function that takes a list of strings and returns the tokenized version of each string\n",
    "    \"\"\"\n",
    "    #counter = 0\n",
    "    #token_pat = re.compile(r'[\\w@’#]+')\n",
    "    token_pat = re.compile(r'\\w+')\n",
    "    skippable_pat = re.compile(r'[\\s\\d]+|@user|(\\w+\\d\\w+)|\\b(?:%s)\\b' % '|'.join(stop_words))\n",
    "\n",
    "    non_white_space = re.compile(r'[^@’#\\w\\s]') #Finds characters that are not white_space nor word characters (nor @’#)\n",
    "    #print(\"these are the tweets\")\n",
    "    #print(tweets)\n",
    "    \n",
    "    # Initialise lists\n",
    "    tokens = []\n",
    "    unmatchable = []\n",
    "\n",
    "# Compile patterns for speedup\n",
    "    token_pat = re.compile(r'\\w+')\n",
    "\n",
    "    tokenlist = []\n",
    "    for i in tweets:\n",
    "        #counter = counter + 1\n",
    "        #print(counter)\n",
    "        #tokens = []\n",
    "        #unmatchable = []\n",
    "        line = i.lower()\n",
    "        #print(\"this is i: \",i)\n",
    "        \n",
    "        while line:\n",
    "            #print(\"this is the line\")\n",
    "            #print(line)\n",
    "            skippable_match = re.search(skippable_pat, line)\n",
    "            if skippable_match and skippable_match.start() == 0:\n",
    "                line = line[skippable_match.end():]\n",
    "            else:\n",
    "                token_match = re.search(token_pat, line)\n",
    "                #print(\"tokens_match\")\n",
    "                #print(token_match)\n",
    "                #print(token_match.start())\n",
    "                if token_match and token_match.start() == 0:\n",
    "                    #print(\"\\nAPPEND IS RUNNING\\n\")\n",
    "                    #print(line[:token_match.end()])\n",
    "                    tokens.append(line[:token_match.end()])\n",
    "                    line = line[token_match.end():]\n",
    "                else:\n",
    "                    unmatchable_end = len(line)\n",
    "                    if skippable_match:\n",
    "                        unmatchable_end = skippable_match.start()\n",
    "                    if token_match:\n",
    "                        unmatchable_end = min(unmatchable_end, token_match.start())\n",
    "                    unmatchable.append(line[:unmatchable_end])\n",
    "                    line = line[unmatchable_end:]\n",
    "        tokenlist.append(tokens)\n",
    "        tokens = []\n",
    "    return(tokenlist)\n",
    "\n",
    "\n",
    "def compare_tokenizers(bool):\n",
    "    if bool==True:\n",
    "        tknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "        j = 0\n",
    "        for i in training_data: \n",
    "            temp = i\n",
    "            diff = difflib.context_diff(tknzr.tokenize(i),token_tweets[j])\n",
    "            #print(\"\".join(diff), end = \"\")\n",
    "            print(i,\"tknzr:\",tknzr.tokenize(i),\"\\ntokenlist:\",token_tweets[j],\"\\n\")\n",
    "            j+=1\n",
    "\n",
    "            \n",
    "def import_(classification_task, file_name):\n",
    "    with open(\"../data/raw/\"+classification_task+\"/\"+file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        temp = [int(line.strip(\"\\n\")) for line in f]\n",
    "    return(temp)\n",
    "\n",
    "\n",
    "def import_and_tokenize(classification_task, file_name):\n",
    "    with open(\"../data/raw/\"+classification_task+\"/\"+file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        temp = [line for line in f]\n",
    "    return(tokenizer(temp))\n",
    "\n",
    "\n",
    "def report_clf_stats(predicted, test, classification_task):\n",
    "    name_dict = {\"offensive\": [\"Not offensive\",\"Offensive\"], \"sentiment\": [\"Negative\", \"Neutral\", \"Positive\"]}\n",
    "    print(metrics.accuracy_score(test, predicted))\n",
    "    print(metrics.classification_report(predicted, test, target_names=name_dict[classification_task]),\"\\n\")\n",
    "    print(metrics.confusion_matrix(test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "### The Offensive Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/raw/offensive/train_text.txt\", 'r', encoding = \"utf-8\")\n",
    "inputlist = [line for line in f]\n",
    "f.close()\n",
    "\n",
    "training_data, validation_data = inputlist[:len(inputlist)//2], inputlist[len(inputlist)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tweets = tokenizer(training_data)\n",
    "print(token_tweets)\n",
    "#print(token_tweets[1])\n",
    "#[print(*i) for i in token_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Comparing our own tokenizer with TweetTokenizer from nltk library\n",
    "<b>Set below value 'see_output' = True for comparison <i>(It'll run for a while)</i></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing our own tokenizer with TweetTokenizer from nltk library\n",
    "# Set below value 'see_output' = True for comparison\n",
    "see_output = True\n",
    "compare_tokenizers(see_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus size of Offensive and sentiment training sets respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wc ../data/raw/offensive/train_text.txt\n",
    "wc ../data/raw/sentiment/train_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Offensive:</b> 11916 lines/tweets, 262370 words <br>\n",
    "<b>Sentiment:</b> 45615 lines/tweets, 877516 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tokenizer function on offensive and sentiment training data to get token count right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/raw/offensive/train_text.txt\", \"r\",  encoding = \"utf-8\",) as f:\n",
    "    offensive_raw = [line for line in f]\n",
    "\n",
    "with open(\"../data/raw/sentiment/train_text.txt\", \"r\",  encoding = \"utf-8\",) as f:\n",
    "    sentiment_raw = [line for line in f]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Below cell line takes some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_tokens = tokenizer(offensive_raw)\n",
    "sentiment_tokens = tokenizer(sentiment_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top 10 most frequent words of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://stackoverflow.com/questions/45019607/count-occurrence-of-a-list-in-a-list-of-lists\n",
    "off_uniq = pd.Series(offensive_tokens).explode().value_counts()\n",
    "sent_uniq = pd.Series(sentiment_tokens).explode().value_counts()\n",
    "\n",
    "print(\"Offensive dataset, top 10 tokens:\",\"\\n\",off_uniq[:10],\"\\n\")\n",
    "print(\"Sentiment dataset, top 10 tokens:\",\"\\n\",sent_uniq[:10])\n",
    "\n",
    "#Turning above pd.series into dataframes, for ease of use later\n",
    "#Transformation found at:https://stackoverflow.com/questions/40224319/pandas-series-to-dataframe-using-series-indexes-as-columns\n",
    "off_uniq = off_uniq.to_frame().reset_index()\n",
    "sent_uniq = sent_uniq.to_frame().reset_index()\n",
    "\n",
    "#Renaming columns in dataframes\n",
    "off_uniq.columns = [\"token\",\"count\"]\n",
    "sent_uniq.columns = [\"token\",\"count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type/token ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Types == Amount of different Tokens in dataset\n",
    "off_types = len(off_uniq[\"token\"])\n",
    "sent_types = len(sent_uniq[\"token\"])\n",
    "print(\"Offensive Types: {}\\nSentiment types: {}\\n\".format(off_types,sent_types))\n",
    "\n",
    "#Tokens == Amount of all \"Words\" in dataset\n",
    "off_token_amount = off_uniq[\"count\"].sum()\n",
    "sent_token_amount = sent_uniq[\"count\"].sum()\n",
    "print(\"Offensive tokens, amount: {}\\nSentiment tokens, amount: {}\\n\".format(off_token_amount, sent_token_amount))\n",
    "\n",
    "#Type/token ratio (=ttratio)\n",
    "off_ttratio = off_types/off_token_amount\n",
    "sent_ttratio = sent_types/sent_token_amount\n",
    "print(\"Offensive type/token ratio: {:.4f}\\nSentiment type/token ratio: {:.4f}\".format(off_ttratio, sent_ttratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types that only occur 1, 2 or 3 times\n",
    "<ul>\n",
    "    <li>Things like Hashtags and misspelled nouns are prevalent, but they, more importantly, contain most of the Types in the vocabulary</li>\n",
    "    <li>Tokens that occur only once make up ~ 50% of the types in both datasets!</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Offensive types w. freq 1, 2, or 3 divided by total types: {:.2f}%\".format(\n",
    "    len(off_uniq.loc[(off_uniq[\"count\"]==1) | (off_uniq[\"count\"]==2) | (off_uniq[\"count\"]==3)])/off_types*100))\n",
    "print(\"Sentiment types w. freq 1, 2, or 3 divided by total types: {:.2f}%\".format(\n",
    "    len(sent_uniq.loc[(sent_uniq[\"count\"]==1) | (sent_uniq[\"count\"]==2) | (sent_uniq[\"count\"]==3)])/sent_types*100))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Offensive types w. freq. just 1 divided by total types: {:.2f}%\".format(len(off_uniq.loc[off_uniq[\"count\"]==1])/off_types*100))\n",
    "print(\"Sentiment types w. freq. just 1 divided by total types: {:.2f}%\".format(len(sent_uniq.loc[sent_uniq[\"count\"]==1])/sent_types*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offensive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "#Loading in offensive x-train, x-test, y-train, y-test\n",
    "\n",
    "# x-train\n",
    "ox_train = import_and_tokenize(\"offensive\", \"train_text.txt\")\n",
    "\n",
    "# x-test\n",
    "ox_test = import_(\"offensive\", \"train_labels.txt\")\n",
    "\n",
    "# y-train\n",
    "oy_train = import_and_tokenize(\"offensive\", \"val_text.txt\")\n",
    "\n",
    "# y-test\n",
    "oy_test = import_(\"offensive\", \"val_labels.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for sgdclassifier\n",
    "sgd_clf = Pipeline([\n",
    "     ('vec', CountVectorizer(tokenizer = lambda x: x, lowercase = False,\n",
    "                ngram_range=(1,3), max_df = 0.7, min_df = 5, max_features = 5000)),\n",
    "     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "     ('clf', SGDClassifier(loss=\"hinge\")),\n",
    "])\n",
    "\n",
    "sgd_clf.fit(ox_train, ox_test)\n",
    "sgd_predicted2 = sgd_clf.predict(oy_train)\n",
    "#sgd_predicted2\n",
    "\n",
    "report_clf_stats(sgd_predicted2, oy_test, \"offensive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Highest Achieved accuracy score for SGDClassifier: 78.6% </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB\n",
    "multinb_clf = Pipeline([\n",
    "     ('vec', CountVectorizer(tokenizer = lambda x: x, lowercase = False)),\n",
    "     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "multinb_clf.fit(ox_train, ox_test)\n",
    "multinb_predict = multinb_clf.predict(oy_train)\n",
    "\n",
    "report_clf_stats(multinb_predict, oy_test, \"offensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ComplementNB\n",
    "complement_clf = Pipeline([\n",
    "     ('vec', CountVectorizer(tokenizer = lambda x: x, lowercase = False)),\n",
    "     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "     ('clf', ComplementNB()),\n",
    "])\n",
    "\n",
    "complement_clf.fit(ox_train, ox_test)\n",
    "complement_predict = complement_clf.predict(oy_train)\n",
    "\n",
    "report_clf_stats(complement_predict, oy_test, \"offensive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes time to run SVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "SVC_clf = Pipeline([\n",
    "     ('vec', CountVectorizer(tokenizer = lambda x: x, lowercase = False)),\n",
    "     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "     ('clf', SVC(kernel='poly', degree = 3)),\n",
    "])\n",
    "\n",
    "SVC_clf.fit(ox_train, ox_test)\n",
    "SVC_predict = SVC_clf.predict(oy_train)\n",
    "\n",
    "report_clf_stats(SVC_predict, oy_test, \"offensive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
